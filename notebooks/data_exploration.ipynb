{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf31e25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "# =========================================================\n",
    "# CONFIGURATION\n",
    "# =========================================================\n",
    "data_paths = {\n",
    "    \"Bot-IoT\": r\"D:\\IoT_IDS_Thesis\\data\\raw\\Bot-IoT\\Bot-IoT_Dataset\\Dataset\\Entire_Dataset\",\n",
    "    \"UNSW-NB15\": r\"D:\\IoT_IDS_Thesis\\data\\raw\\UNSW-NB15\\UNSW-NB15 dataset\\CSV Files\\Training and Testing Sets\\UNSW_NB15_training-set.csv\",\n",
    "    \"TON_IoT\": r\"D:\\IoT_IDS_Thesis\\data\\raw\\TON_IoT\\Train_Test_datasets\\Train_Test_Network_dataset\\train_test_network.csv\"\n",
    "}\n",
    "\n",
    "output_dir = r\"D:\\IoT_IDS_Thesis\\data\\docs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "datasets = {}\n",
    "metadata = {}\n",
    "\n",
    "# =========================================================\n",
    "# BOT-IoT DTYPES (MEMORY OPTIMIZED)\n",
    "# =========================================================\n",
    "bot_iot_dtypes = {\n",
    "    'pkSeqID': 'int32',\n",
    "    'stime': 'float32',\n",
    "    'flgs': 'category',\n",
    "    'proto': 'category',\n",
    "    'saddr': 'category',\n",
    "    'sport': 'object',\n",
    "    'daddr': 'category',\n",
    "    'dport': 'object',\n",
    "    'pkts': 'int32',\n",
    "    'bytes': 'int64',\n",
    "    'state': 'category',\n",
    "    'ltime': 'float32',\n",
    "    'dur': 'float32',\n",
    "    'mean': 'float32',\n",
    "    'stddev': 'float32',\n",
    "    'sum': 'float32',\n",
    "    'min': 'float32',\n",
    "    'max': 'float32',\n",
    "    'spkts': 'int32',\n",
    "    'dpkts': 'int32',\n",
    "    'sbytes': 'int64',\n",
    "    'dbytes': 'int64',\n",
    "    'rate': 'float32',\n",
    "    'attack': 'int8',\n",
    "    'category': 'category',\n",
    "    'subcategory': 'category'\n",
    "}\n",
    "\n",
    "BOT_IOT_LABELS = ['attack', 'category', 'subcategory']\n",
    "\n",
    "# =========================================================\n",
    "# LOAD BOT-IoT (CHUNKED)\n",
    "# =========================================================\n",
    "print(\"\\nüîπ Loading Bot-IoT dataset...\")\n",
    "bot_iot_folder = data_paths[\"Bot-IoT\"]\n",
    "\n",
    "label_dists = {k: defaultdict(int) for k in BOT_IOT_LABELS}\n",
    "missing_total = pd.Series(0, index=bot_iot_dtypes.keys())\n",
    "total_rows = 0\n",
    "samples = []\n",
    "\n",
    "csv_files = glob.glob(os.path.join(bot_iot_folder, \"**/*.csv\"), recursive=True)\n",
    "\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        for chunk in pd.read_csv(\n",
    "            file,\n",
    "            dtype=bot_iot_dtypes,\n",
    "            low_memory=False,\n",
    "            chunksize=100_000\n",
    "        ):\n",
    "            total_rows += len(chunk)\n",
    "            missing_total += chunk.isna().sum()\n",
    "\n",
    "            for lbl in BOT_IOT_LABELS:\n",
    "                if lbl in chunk.columns:\n",
    "                    for k, v in chunk[lbl].value_counts().items():\n",
    "                        label_dists[lbl][k] += v\n",
    "\n",
    "            if len(samples) < 5:\n",
    "                samples.append(chunk.head(1000))\n",
    "\n",
    "        print(f\"   ‚úÖ Processed {os.path.basename(file)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error processing {file}: {e}\")\n",
    "\n",
    "datasets[\"Bot-IoT\"] = pd.concat(samples, ignore_index=True)\n",
    "metadata[\"Bot-IoT\"] = {\n",
    "    \"total_rows\": total_rows,\n",
    "    \"missing_total\": missing_total,\n",
    "    \"label_dists\": {k: pd.Series(v) for k, v in label_dists.items()}\n",
    "}\n",
    "\n",
    "print(f\"‚úî Bot-IoT rows: {total_rows:,} (sample loaded: {datasets['Bot-IoT'].shape})\")\n",
    "\n",
    "# =========================================================\n",
    "# LOAD OTHER DATASETS\n",
    "# =========================================================\n",
    "for name in [\"UNSW-NB15\", \"TON_IoT\"]:\n",
    "    print(f\"\\nüîπ Loading {name}...\")\n",
    "    df = pd.read_csv(data_paths[name], low_memory=False)\n",
    "    datasets[name] = df\n",
    "    metadata[name] = {\n",
    "        \"total_rows\": len(df),\n",
    "        \"missing_total\": df.isna().sum(),\n",
    "        \"label_dists\": None\n",
    "    }\n",
    "    print(f\"   ‚úÖ Loaded {df.shape}\")\n",
    "\n",
    "# =========================================================\n",
    "# CLEANING FUNCTIONS\n",
    "# =========================================================\n",
    "def clean_dataset(df):\n",
    "    df = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]\n",
    "    df.columns = df.columns.str.strip().str.replace(\" \", \"_\").str.replace(\".\", \"_\")\n",
    "    df = df.loc[:, df.nunique() > 1]\n",
    "    return df\n",
    "\n",
    "for name in datasets:\n",
    "    datasets[name] = clean_dataset(datasets[name])\n",
    "    print(f\"üßπ Cleaned {name}: {datasets[name].shape}\")\n",
    "\n",
    "# =========================================================\n",
    "# STANDARDIZE COLUMN NAMES\n",
    "# =========================================================\n",
    "rename_map = {\n",
    "    'saddr': 'src_ip',\n",
    "    'sport': 'src_port',\n",
    "    'daddr': 'dst_ip',\n",
    "    'dport': 'dst_port',\n",
    "    'dur': 'duration',\n",
    "    'sbytes': 'src_bytes',\n",
    "    'dbytes': 'dst_bytes'\n",
    "}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns}, inplace=True)\n",
    "\n",
    "# =========================================================\n",
    "# DATASET OVERVIEW\n",
    "# =========================================================\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{name} DATASET OVERVIEW\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Records: {metadata[name]['total_rows']:,}\")\n",
    "    print(f\"Features: {df.shape[1]}\")\n",
    "    print(f\"Memory (sample): {df.memory_usage(deep=True).sum()/1024**2:.2f} MB\")\n",
    "    print(df.head(5).to_string())\n",
    "\n",
    "# =========================================================\n",
    "# LABEL ANALYSIS (SAFE)\n",
    "# =========================================================\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\nüîé {name} - Label Analysis\")\n",
    "\n",
    "    if name == \"Bot-IoT\":\n",
    "        label_cols = BOT_IOT_LABELS\n",
    "        label_dists = metadata[name]['label_dists']\n",
    "    else:\n",
    "        label_cols = [c for c in df.columns if 'label' in c.lower() or 'class' in c.lower()]\n",
    "\n",
    "    if not label_cols:\n",
    "        print(\"   ‚ö†Ô∏è No label columns found\")\n",
    "        continue\n",
    "\n",
    "    for lbl in label_cols:\n",
    "        print(f\"\\n--- {lbl} ---\")\n",
    "\n",
    "        if name == \"Bot-IoT\":\n",
    "            counts = label_dists.get(lbl, pd.Series())\n",
    "        else:\n",
    "            counts = df[lbl].value_counts()\n",
    "\n",
    "        if counts.empty:\n",
    "            print(\"   ‚ö†Ô∏è Empty distribution, skipping plot\")\n",
    "            continue\n",
    "\n",
    "        print(counts.head(10).to_string())\n",
    "\n",
    "        if len(counts) <= 20:\n",
    "            counts.astype(int).plot(kind='bar')\n",
    "            plt.title(f\"{name} - {lbl}\")\n",
    "            plt.ylabel(\"Count (log scale)\")\n",
    "            plt.yscale(\"log\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "# =========================================================\n",
    "# BASIC ML PREPROCESSING (SAMPLE SAFE)\n",
    "# =========================================================\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\n‚öôÔ∏è Preprocessing {name}...\")\n",
    "\n",
    "    num_cols = df.select_dtypes(include=np.number).columns\n",
    "    df[num_cols] = df[num_cols].fillna(df[num_cols].mean())\n",
    "\n",
    "    cat_cols = [c for c in ['proto', 'service'] if c in df.columns]\n",
    "    if cat_cols:\n",
    "        df = pd.get_dummies(df, columns=cat_cols)\n",
    "\n",
    "    datasets[name] = df\n",
    "    print(\"   ‚úÖ Done\")\n",
    "\n",
    "# =========================================================\n",
    "# FINAL SUMMARY\n",
    "# =========================================================\n",
    "summary = []\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    summary.append({\n",
    "        \"Dataset\": name,\n",
    "        \"Total_Rows\": metadata[name]['total_rows'],\n",
    "        \"Features\": df.shape[1],\n",
    "        \"Numeric_Features\": len(df.select_dtypes(include=np.number).columns),\n",
    "        \"Categorical_Features\": len(df.select_dtypes(include=['object', 'category']).columns),\n",
    "        \"Missing_Values\": int(metadata[name]['missing_total'].sum()),\n",
    "        \"Memory_MB\": round(df.memory_usage(deep=True).sum()/1024**2, 2)\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "print(\"\\nüìå FINAL SUMMARY\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "summary_path = os.path.join(output_dir, \"dataset_analysis_summary.csv\")\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "print(f\"\\nüíæ Summary saved to: {summary_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
